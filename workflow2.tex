\documentclass{report}
\usepackage[landscape]{geometry}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage[inline]{enumitem}
\usepackage{tikz}
\usetikzlibrary{calc,shapes, positioning,arrows}

\usepackage{bibleref}

\usepackage{minted1}
%\usepackage{minted}
\usepackage{listings}
\newcommand{\mi}[1]{\lstinline{#1}}

\makeatletter
\newenvironment{python}{%
  \VerbatimEnvironment
  \minted@resetoptions
  \setkeys{minted@opt}{}
      \begin{VerbatimOut}{\jobname.pyg}}
{%
      \end{VerbatimOut}
      \minted@pygmentize{python}
      \DeleteFile{\jobname.pyg}}
\makeatother

\usepackage{multicol}

%\usepackage[usenames, dvipsnames]{color}
%\newcommand{\fixme}[1]{{#1}}

\title{Work flow with gcdata.sqlite and several Python scripts}
\author{Grietje Commelin}

\begin{document}
\maketitle

\noindent
In this document I try to explain the work flow that I follow to gather, improve and use data about participant references by running Python scripts on the ETCBC database and my own gcdata.sqlite.\\
Data is indicated with red frames, and scripts with blue ones.

\begin{tikzpicture}[outline/.style={draw=#1,thick,fill=#1!50},>=stealth',thick,black!50,text=black,every new ->/.style={shorten >=.3cm}]
\centering

\node [outline=red] (input) {ETCBC4 data};
\node [outline=blue](part1) [below = of input]{Part-1.py};
\draw [shorten > =.1cm, ->] (input.south) -- (part1.north);
\node[outline=blue](qf) [below right = of input]{DSU+QF.py};
\draw [shorten > =.3cm, ->] (input.south) -- (qf.north);
\node[dashed, outline=blue, fill opacity =.5](enc) [below left = of input]{encoding\_options.py};
\draw [dashed, shorten > =.3cm, ->] (input.south) -- (enc.north);

\node [outline=red] (pt) [below=of part1]{gcdata.pt};
\draw [shorten > =.1cm, ->] (part1) -- (pt);

\node [dashed, outline=red, fill opacity =.5](enc2)[below = of enc]{gcdata.enc};
\draw [dashed, shorten > =.1cm, ->] (enc.south) -- (enc2.north);
\draw [dashed, shorten > =.1cm, ->] (enc2.east) -- (part1.west);

\node [outline=red] (gcdsu) [below=of qf]{gcdata.gcdsu};
\draw [shorten > =.1cm, ->] (qf.south) -- (gcdsu.north);
\node [outline=blue] (part2) [below = of pt] {Part-2.py};
\draw [shorten > =.1cm, ->] (pt) to [bend right = 20] (part2.north);
\draw [shorten > =.1cm, ->] (part2.north) to [bend right = 20] (pt);
\draw [shorten > =.1cm, ->] (gcdsu.south west) to [bend right = 20] (part2.north east);
\draw [shorten > =.1cm, ->] (part2.north east) to [bend right = 20] (gcdsu.south west);

\node [outline=green](show)[below = of part2]{Display of text with data};
\draw [shorten > =.1cm, ->] (gcdsu) to [bend left = 40] (show);
\draw [shorten > =.1cm, ->] (pt) to [bend right = 60] (show.west);
\draw [dashed, shorten > =.1cm, ->] (show.south) to [bend right = 120] (input);
\end{tikzpicture}

\chapter{Packages and LAF data that have to be loaded for executing the scripts}

\begin{python}
#{{{ Import all important libraries
import os, sys, time
if not '/projects/1fdd6b0b-5199-4b0e-9f7f-7759af4a5e7a/.local/lib/python3.4/site-packages/' in sys.path:
    sys.path.append('/projects/1fdd6b0b-5199-4b0e-9f7f-7759af4a5e7a/.local/lib/python3.4/site-packages/')
import collections
import random
import laf
from copy import deepcopy
from laf.fabric import LafFabric
import etcbc
from etcbc.preprocess import prepare
from etcbc.lib import Transcription, monad_set
from etcbc.trees import Tree
from etcbc.featuredoc import FeatureDoc
fabric = LafFabric()
tr = Transcription()

print("It works so far." )
#}}}
\end{python}

\begin{python}
#{{{ Load the API
API = fabric.load("etcbc4", "--", "feature-doc", {
    "xmlids": {"node": False, "edge": False},
    "features": ('''
            otype
            domain
            function
            g_cons
            g_cons_utf8
            g_lex
            g_lex_utf8
            g_nme
            g_nme_utf8
            g_pfm
            g_pfm_utf8
            g_prs
            g_prs_utf8
            g_uvf
            g_uvf_utf8
            g_vbe
            g_vbe_utf8
            g_vbs
            g_vbs_utf8
            g_word
            g_word_utf8
            gn
            lex
            lex_utf8
            ls
            nme
            nu
            number
            pdp
            pfm
            prs
            ps
            rela
            sp
            st
            tab
            trailer_utf8
            txt
            typ
            uvf
            vbe
            vbs
            vs
            vt
            book
            chapter
            label
            verse
    ''','''
            mother
    '''),
    "primary": False,
    "prepare": prepare,
})
exec(fabric.localnames.format(var='fabric'))

#}}}
\end{python}

\begin{python}
#{{{ Stuff necessary to load parents relationships
type_info = (
    ("word", ''),
    ("subphrase", 'U'),
    ("phrase", 'P'),
    ("clause", 'C'),
    ("sentence", 'S'),
)
type_table = dict(t for t in type_info)
type_order = [t[0] for t in type_info]

pos_table = {
    'adjv': 'aj',
    'advb': 'av',
    'art': 'dt',
    'conj': 'cj',
    'intj': 'ij',
    'inrg': 'ir',
    'nega': 'ng',
    'subs': 'n',
    'nmpr': 'n-pr',
    'prep': 'pp',
    'prps': 'pr-ps',
    'prde': 'pr-dem',
    'prin': 'pr-int',
    'verb': 'vb',
}

ccr_info = {
    'Adju': ('r', 'Cadju'),
    'Attr': ('r', 'Cattr'),
    'Cmpl': ('r', 'Ccmpl'),
    'CoVo': ('n', 'Ccovo'),
    'Coor': ('x', 'Ccoor'),
    'Objc': ('r', 'Cobjc'),
    'PrAd': ('r', 'Cprad'),
    'PreC': ('r', 'Cprec'),
    'Resu': ('n', 'Cresu'),
    'RgRc': ('r', 'Crgrc'),
    'Spec': ('r', 'Cspec'),
    'Subj': ('r', 'Csubj'),
    'NA':   ('n', 'C'),
}

tree_types = ('sentence', 'clause', 'clause_atom', 'phrase', 'subphrase', 'word')
(root_type, leaf_type, clause_type) = (tree_types[0], tree_types[-1], 'clause')
ccr_table = dict((c[0],c[1][1]) for c in ccr_info.items())
ccr_class = dict((c[0],c[1][0]) for c in ccr_info.items())

root_verse = {}
root_clause_atom = {}

for n in NN():
    otype = F.otype.v(n)
    if otype == "book" and F.etcbc4_sft_book.v(n) != "Genesis":
        break
    elif otype == "chapter" and int(F.etcbc4_sft_chapter.v(n)) > 5:
        break
    elif otype == "verse": cur_verse = F.label.v(n)
    elif otype == "clause_atom":
        root_verse[n] = cur_verse
        cur_clause_atom = F.etcbc4_ft_number.v(n)
    elif otype == "word":
        root_verse[n] = cur_verse
        root_clause_atom[n] = cur_clause_atom
#        print(list(C.parent.v(n)))

tree = Tree(API, otypes = tree_types,
     clause_type=clause_type,
     ccr_feature='rela',
     pt_feature='typ',
     pos_feature='sp',
     mother_feature = 'mother',
     )
#tree.restructure_clauses(ccr_class)
results = tree.relations()
parent = results['eparent']
sisters = results['sisters']
children = results['echildren']
elder_sister = results['elder_sister']
print("Ready for processing") # Was msg()
#}}}
\end{python}

\begin{python}
#{{{ Import the helper functions

def give_me_your_daughters(n):
        global F
        daughters = []
        for x in Ci.mother.v(n):
            daughters.append(x)
            if list(Ci.mother.v(x)) != []:
                daughters += give_me_your_daughters(x)
        return(daughters)

def give_me_your_words(n):
        global F
        if F.etcbc4_db_otype.v(n) == 'word':
                return [n]
        else:
            list_of_word_lists = [give_me_your_words(c) for c in children[n]]
            return [item for sublist in list_of_word_lists for item in sublist]

def give_me_your_subphrases(n):
        global F
        subphrases = []
        for x in children[n]:
            if F.etcbc4_db_otype.v(x) == "subphrase":
                subphrases.append(x)
            if children[x] != []:
                subphrases += give_me_your_subphrases(x)
        return subphrases

def get_text_of_word_list(word_list):
        global F
        return ' '.join(map(F.etcbc4_ft_g_cons_utf8.v, word_list))

def get_cons_of_word_list(word_list):
        global F
        return ' '.join(map(F.etcbc4_ft_g_cons.v, word_list))

def give_me_your_parents_up_to(node, parent_type='clause', limit=19):
    # This function is very dangerous. If you feed it something larger than a clause, stuff explodes.
        global parent
        if limit < 0:
                return []
        if not node in parent:
                return ["not in parent"]
        p = parent[node]
        if F.etcbc4_db_otype.v(p) == parent_type:
                return [p]
        else:
                return [p] + give_me_your_parents_up_to(p, parent_type, limit-1)

suffix_dict = {
'W'   : { 'ps' : 'p3', 'nu' : 'sg', 'gn' : 'm' },
'K'   : { 'ps' : 'p2', 'nu' : 'sg', 'gn' : 'm' },
'J'   : { 'ps' : 'p1', 'nu' : 'sg', 'gn' : 'unknown' },
'M'   : { 'ps' : 'p3', 'nu' : 'pl', 'gn' : 'm' },
'H'   : { 'ps' : 'p3', 'nu' : 'sg', 'gn' : 'f' },
'HM'  : { 'ps' : 'p3', 'nu' : 'pl', 'gn' : 'm' },
'KM'  : { 'ps' : 'p2', 'nu' : 'pl', 'gn' : 'm' },
'NW'  : { 'ps' : 'p1', 'nu' : 'pl', 'gn' : 'unknown' },
'HW'  : { 'ps' : 'p3', 'nu' : 'sg', 'gn' : 'm' },
'NJ'  : { 'ps' : 'p1', 'nu' : 'sg', 'gn' : 'unknown' },
'K='  : { 'ps' : 'p2', 'nu' : 'sg', 'gn' : 'f' },
'HN'  : { 'ps' : 'p3', 'nu' : 'pl', 'gn' : 'f' },
'H='  : { 'ps' : 'p3', 'nu' : 'sg', 'gn' : 'unknown' },
'MW'  : { 'ps' : 'p3', 'nu' : 'pl', 'gn' : 'm' },
'N'   : { 'ps' : 'p3', 'nu' : 'pl', 'gn' : 'f' },
'KN'  : { 'ps' : 'p2', 'nu' : 'pl', 'gn' : 'f' },
}

def insert_dict_in_db(cursor, table, values):
        columns = ', '.join(values.keys())
        placeholders = ':'+', :'.join(values.keys())
        query = 'INSERT INTO %s (%s) VALUES (%s)' % (table, columns, placeholders)
#        print(query)
        cursor.execute(query, values)

#}}}
\end{python}

\chapter{DSU+QF.py}
\lstset{language=python,basicstyle=\ttfamily}

\begin{multicols}{2}
In this task I want to extract information from the ETCBC database + ask for user-input about DSU's and QF's + put it into an SQLite-table.
A DSU is a Direct Speech Unit, and a QF is a Quotative Frame.

\textbf{WARNING:} DSU's are found on the basis of \mi{text_type}s of \mi{clause_atom}s as stored in the ETCBC database. However, testing shows that these are not 100\% correct and will need improvement.

\textbf{WARNING2:} This task assumes that a DSU ends when the embedding (number of \mi{Q}'s in the \mi{text_type} of a \mi{clause_atom}) decreases.
However, it might very well be possible that various DSU's follow each other on the same level of embedding without intervening lower-\mi{Q} \mi{clause_atom}s.
At the moment these cases will not be detected by this script!
\end{multicols}

\begin{python}
#{{{ Create an SQLite-table with a row for every QF + DSU, and columns for useful information about these DSU's.
import json as j
import sqlite3
db = sqlite3.connect('gcdata.sqlite')
cursor = db.cursor()

create_table_query = open('gcdsu.sql').read()

cursor.execute(create_table_query)

db.commit()
#}}}
\end{python}

\begin{multicols}{2}
Now we want to determine which \mi{clause_atom_number}s constitute QF's, and gather \mi{user_input} about them.
\begin{itemize}
 \item Show 4 clauses before DSU + first 4 clauses of DSU itself, all with \mi{clause_atom_number} and \mi{g_consonants}.
 \item Ask for block of \mi{clause_atom}s before DSU:
 \begin{itemize}
    \item Which \mi{clause_atom}s (if any) are QF
    \item What ``MySp" is. Can be any name
    \item What ``QFSp" is. Can be anything, or ""
    \item What ``QFSptype" is. Options: \mi{Noun}, \mi{Noun_phrase}, \mi{Name}, \mi{Name_phrase}, \mi{Pers_pronoun}, \mi{Suffix}, \mi{Verb}
    \item What ``MyAd" is. Can be any name
    \item What ``QFAd" is. Can be anything, or ""
    \item What ``QFAdtype" is. Options: \mi{Noun}, \mi{Noun_phrase}, \mi{Name}, \mi{Name_phrase}, \mi{Pers_pronoun}, \mi{Suffix}, \mi{Verb}
    \item What ``QFAdprep" is
    \item What ``QFplus" is. Can be anything, or \mi{NULL}
    \item What ``QFplustype" is. Can be something like \mi{Time} or \mi{Space}, or \mi{NULL}
  \end{itemize}
\end{itemize}
\end{multicols}

\begin{python}
def verbs(QFClANrs):
    QFverb,QFverbspeech,QFLMR = [],[],"No"
    for x in QFClANrs.split(","):
        if not x in (""," ","  "):
            for y in give_me_your_words(int(x)):
                if F.etcbc4_ft_sp.v(y) == "verb":
                    QFverb.append(y)
                    if F.etcbc4_ft_ls.v(y) == "quot":
                        QFverbspeech.append(y)
                        if F.etcbc4_ft_lex.v(y) == ">MR[" and F.etcbc4_ft_vt.v(y) == "infc":
                            QFLMR = "Yes"
    return(','.join(str(x) for x in QFverb),','.join(str(x) for x in QFverbspeech),QFLMR)

\end{python}

\begin{python}
def process_DSU(ClANrs, potential_QF, place,prev_context,context,level):
    DSUdata = {}
    print(place)
    print("Potential QF:")  # Show the clause_atom_numbers of potential_QF with their text
    for x in potential_QF:
        print('{0:<3} {1:<8} {2:>35} {3} {4:<35}'.format(potential_QF.index(x), x, get_text_of_word_list(give_me_your_words(x))," | ", get_cons_of_word_list(give_me_your_words(x))))
    print("Start of DSU:")  # Show the first clause_atom_numbers and text of the DSU
    for y in ClANrs[:3]:
        print('{0:<11} {1:>35} {2} {3:<35}'.format(y, get_text_of_word_list(give_me_your_words(y))," | ",get_cons_of_word_list(give_me_your_words(y))))
    print("-"*20)
    DSUdata["a"] = place
    DSUdata["Level"] = level
    DSUdata["ClANrs"] = ','.join(str(x) for x in ClANrs)
#    DSUdata["ClANrs"] = repr(ClANrs)
    DSUdata["Con1"] = prev_context
    DSUdata["Con2"] = context
    QFClANrs1 = input("Clause_atoms that are indeed QF (type comma-separated numbers): ") or ""
    QFClANrs2 = ""
    if QFClANrs1 == "":
        DSUdata["QFClANrs"] = ""
    else:
        for y in QFClANrs1.split(","):
            QFClANrs2 += str(potential_QF[int(y)]) + ","
        DSUdata["QFClANrs"] = QFClANrs2
    DSUdata["QFverb"],DSUdata["QFverbspeech"],DSUdata["QFLMR"] = verbs(DSUdata["QFClANrs"])
    DSUdata["QFSp"] = input("QFSp: ") or ""
    DSUdata["QFSptype"] = input("QFSptype (1=Noun, 2=Noun_phrase, 3=Name, 4=Name_phrase, 5=Pers_pronoun, 6=Other_pronoun, 7=Suffix, 8=Verb): ") or None
    DSUdata["MySp"] = repr(input("MySp: ,default " + DSUdata["QFSp"]).split(",")) or DSUdata["QFSp"]
    DSUdata["QFAd"] = input("QFAd: ") or ""
    DSUdata["QFAdtype"] = input("QFAdtype (1=Noun, 2=Noun_phrase, 3=Name, 4=Name_phrase, 5=Pers_pronoun, 6=Other_pronoun, 7=Suffix, 8=Verb): ") or None
    DSUdata["QFAdprep"] = input("QFAdprep: ") or None
    DSUdata["MyAd"] = repr(input("MyAd: ,default " + DSUdata["QFAd"]).split(",")) or DSUdata["QFAd"]
    DSUdata["QFplus"] = input("QFplus: ") or None
    DSUdata["QFplustype"] = input("QFplustype: ") or None
    DSUdata["Start_node"] = ClANrs[0]
    DSUdata["DSUtag"] = str(DSUdata["Start_node"]) + str(DSUdata["Level"])
    if DSUdata["QFClANrs"] != "":
        DSUdata["QF"] = "Yes"
    elif DSUdata["QFClANrs"] == "":
        DSUdata["QF"] = "No"
    insert_dict_in_db(cursor, "gcdsu", DSUdata)

\end{python}

\begin{python}
def main_loop():
    ClANrs =       [[],[],[],[],[],[],[],[]]
    potential_QF = [[],[],[],[],[],[],[],[]]
    pot_QF = []
    context = ""
    prev_context = ["","","","","","","",""]
    place = None
    places =       ["","","","","","","",""]
    level = 0
    completed = False
    check_node = ""
    for node in NN():
        otype = F.etcbc4_db_otype.v(node)
        if otype == "book" and F.etcbc4_sft_book.v(node) != "Genesis":
            break
        elif otype == "chapter":
            if int(F.etcbc4_sft_chapter.v(node)) < 2:    # Prevent re-doing already completed chapters
                completed = True
#            elif int(F.etcbc4_sft_chapter.v(node)) > 3:    # Set a limit on the amount of data dealt with this time
#                break
            else:
                completed = False
        elif otype == "verse" and completed == False:
            place = F.etcbc4_sft_label.v(node)
        elif otype == "clause" and completed == False:
            prev_level = level
            level = F.etcbc4_ft_txt.v(node).count("Q")      # Determine level by parsing text_type data
            previous_context = context
            context = F.etcbc4_ft_txt.v(node)
        elif otype == "clause_atom" and completed == False:
            pot_QF.append(node)     # Update pot_QF
            if len(pot_QF) > 5:
                del pot_QF[0]       # Keep length of pot_QF reasonable
            if level > 0:           # At least one DSU under construction
                for i in range(1,(level+1)):
                    ClANrs[level].append(node)   # For all DSU's under construction, add current ClANr to list of ClANrs
            if prev_level < level:                  # Start of new DSU
                places[level] = place               # Store starting place of new DSU
                potential_QF[level] = pot_QF[:-1]   # Store potential QF of new DSU
                prev_context[level] = previous_context    # Store context (preceding text_type)
            elif prev_level > level:                # End of one or more DSU's
                for j in range((level+1),(prev_level+1)): # Process the DSU's that end here
                    check_node = str(ClANrs[j][0])
                    cursor.execute("SELECT EXISTS (SELECT * FROM gcdsu WHERE Start_node = " + check_node + ");") # Check whether DSU is not yet saved in database
                    result = cursor.fetchone()
                    if result == (0,):
                        process_DSU(ClANrs[j], potential_QF[j],places[j],prev_context[j],context,j)
                    ClANrs[j], potential_QF[j], places[j], prev_context[j] = [],[],"",""    # Delete all stored data

\end{python}

\begin{python}
#{{{ Execute main loop
main_loop()
#}}}

#{{{ Wrap up the database connection
db.commit()
cursor.close()
#}}}
\end{python}

\chapter{encoding\_options.py}
\chapter{Part-1.py}
The chapter \mi{DSU+QF} above was about DSU's. This chapter is about participant references within them, that are dealt with one by one or as a `clan'. There are a lot of scripts that together form an interactive procedure in which much data about each participant reference is gathered and stored in the sqlite table \mi{gcdata.pt}.

First we want to set up the database connection, if this was not yet done by the scripts about DSU's.
\begin{python}
# Setup the database stuff
import sqlite3

db = sqlite3.connect('gcdata.sqlite')
cursor = db.cursor()

#create_table_query = open("pt.sql").read()
#cursor.execute(create_table_query)

db.commit()

\end{python}

Now we have several functions that together gather information about participant references, and some functions to manage the workflow of all these references. The order of these functions is not intuitive, because functions used by other functions need to be declared before they can be used. A short overview might help; blue boxes are scripts, the red one is an sqlite table. Scripts indicated with a * are embedded within another one, and therefore included in a larger box.

\begin{tikzpicture}[outline/.style={draw=#1,thick,fill=#1!50},
>=stealth',thick,black!50,text=black,every new ->/.style={shorten >=.3cm}]
\centering
\node [outline=blue] (basic) {Basic script};
\node [outline=blue, text width=5.5em] (flow) [below left = of basic] {Flow\_clan *Prepare **Recognize};
\draw [shorten > = .1cm, ->] (basic.south) -- (flow.north);

\node [outline=blue, text width=7.5em] (clan) [below = of flow] {Interactive\_clan *Add\_data *Recognize2};
\draw [shorten > = .1cm, ->] (flow.south) -- (clan.north);

\node [outline=red] (pt) [below right = of clan] {gcdata.pt};
\draw [shorten > = .1cm, ->] (clan.south) -- (pt.north);

\node [outline=blue, text width = 5.5em] (prepare2) [below right = of basic] {Prepare *Recognize};
\draw [shorten > = .1cm, ->] (basic.south) -- (prepare2.north);
\node [outline=blue, text width = 7.5em] (single) [below = of prepare2] {Interactive\_single *Add\_data};
\draw [shorten > = .1cm, ->] (prepare2.south) -- (single.north);
\draw [shorten > = .1cm, ->] (single.south) -- (pt.north);

\end{tikzpicture}

\begin{tabularx}{\textwidth}{lX}
Basic script & Script that loops over the Hebrew text to select potential participant references that need to be dealt with.\\
Flow\_clan & Overarching flow for clans to let the computer create as much data as possible about selected participant references (with REG-rectum data) and do a proposal to the user \\
Interactive\_clan & This function asks interactively for input about references that are related to each other, i.e. that form a multi-layered `clan'. Several proposals are shown, and can be accepted, rejected or adapted. \\
Interactive\_single & This function asks interactively for input about suffixes that are not part of a larger `clan' (i.e. a multi-layered reference), but occur on their own. \\
Prepare & Some basic information about a reference, that can be found automatically, is gathered before the start of the interactive procedure.\\
Recognize & If a participant has already been treated before, it is likely that some personal data has remained the same, and can therefore be re-used in the participant reference currently under consideration. This procedure of re-using already entered information also helps guard consistency. \\
Add\_data & Automatically add data to entries that are going to be fed to gcdata.pt \\
\end{tabularx}


\begin{python}
def recognize(Des):
    Recognize = []
    print(Des)
    Recognize = list(cursor.execute("select Name,Anim,Human,Col from pt where Des=:Des and not Destype=8 ORDER BY Tag DESC LIMIT 1", {"Des":Des, }))
    if Recognize == []:
        return []
    else:
        return Recognize

\end{python}

\begin{python}
def recognize2(Name):
    Recognize = []
    Recognize = list(cursor.execute("select Anim,Human,Col from pt where Name=:Name ORDER BY Tag DESC LIMIT 1", {"Name":Name, }))
    if Recognize == []:
        return []
    else:
        return Recognize

\end{python}

\begin{python}
def prepare(place, candidate, node_type, sub):
    cand = candidate
    if str(candidate).endswith("s") or str(candidate).endswith("c") or str(candidate).endswith("d"): # Suffix or copied reference
        cand = int(candidate[:-1]) # If the `candidate' is not a node number, we have to make it so before we are able to retrieve certain information from the database.
    Recognize = []
#    current = data[candidate]
    if node_type == "word+": # Reference is a word or higher-level reference
        current= {}
        current["Des"] = get_cons_of_word_list(give_me_your_words(cand))
        current["a"] = place
        current["Node"] = candidate
        nodetype = F.etcbc4_db_otype.v(cand)
        if nodetype == "word":
            current["Nodetype"] = "2"
            current["Role"] = F.etcbc4_ft_function.v(L.u('phrase',cand))
        elif nodetype in ("subphrase", "phrase", "phrase_atom"):
            current["Nodetype"] = "3"
            current["Role"] = F.etcbc4_ft_function.v(cand)
        elif nodetype in ("clause","clause_atom"):
            current["Nodetype"] = "4"
        if not get_cons_of_word_list(give_me_your_words(cand)) == "KL" and not F.etcbc4_ft_sp.v(cand) == "verb": # `KL' is not an independent reference, so the person it refers to is different every time. Therefore it is useless to run the function `Recognize' in this case. Same for verbs: they usually have different subjects the next time.
            Recognize = recognize(get_cons_of_word_list(give_me_your_words(cand)))
        if not Recognize == []:
            current["Name"] = Recognize[0][0]
            current["Anim"] = Recognize[0][1]
            current["Human"] = Recognize[0][2]
            current["Col"] = Recognize[0][3]
        if not F.etcbc4_ft_prs.v(cand) in ("absent","n/a"): # Reference has a suffix
            if str(sub) in ("None", ""):
                sub = "Super1"
            else:
                sub = str(sub) + "Super1"
        current["Sub"] = sub
    else: # Reference is a suffix
        current = {}
        current["Des"] = F.etcbc4_ft_prs.v(cand)
        current["Nodetype"] = "1"
        current["a"] = place
        current["Node"] = int(cand)
        current["Destype"] = "7"
        if str(sub) not in ("", "None"):
            current["Sub"] = sub
        else:
            current["Sub"] = "Rec" # Most probable role for a suffix
        if F.etcbc4_ft_function.v(L.u('phrase',cand)) in ("ExsS","IntS","ModS","NCoS","PrcS","PreS"):
            current["Role"] = "Subject"
        elif F.etcbc4_ft_function.v(L.u('phrase',cand)) in ("PreO","PtcO"):
            current["Role"] = "Object"
        else:
            current["Role"] = "Pos ?" # Will be checked interactively
    return(current)

\end{python}

\begin{python}
""" In order to avoid problems with candidates that are not a node number 
    (but, for example, have an `s' attached to it), in this function we
    do not use `candidate' to retrieve data from the database, but
    `data[candidate]["Node"]'.
"""
def add_data(data,candidate):
#    cand = candidate
#    if str(candidate).endswith("s") or str(candidate).endswith("c") or str(candidate).endwith("d"):
#        cand = candidate[:-1]
    current = data[candidate]
    if current["Nodetype"] == "4":
        ClANr = current["Node"]
        current["Cltype"] = F.etcbc4_ft_typ.v(current["Node"])
    else:
        ClANr = L.u('clause_atom',current["Node"])
        current["Cltype"] = F.etcbc4_ft_typ.v(L.u('clause',current["Node"]))
    current["ClANr"] = ClANr
    current["Emb"] = F.etcbc4_ft_tab.v(ClANr)
    if current["Nodetype"] in ("1","2"): # Smaller than phrase, so can have PhANr
        current["PhANr"] = L.u('phrase',current["Node"])
    elif current["Nodetype"] == "3": # phrase:
        current["PhANr"] = current["Node"]
        current["Phtype"] = F.etcbc4_ft_typ.v(current["Node"])
        if current["Phtype"] == None: # Apparently node is a subphrase, not a phrase
            current["Phtype"] = F.etcbc4_ft_typ.v(L.u('phrase',current["Node"]))
        current["Phfunc"] = F.etcbc4_ft_function.v(current["Node"])
        if F.etcbc4_db_otype.v(current["Node"]) == 'subphrase':
            current["SPhNr"] = current["Node"]
        else:
            current["SPhNr"] = None
        current["WNr"] = None
    if current["Nodetype"] in ("1","2"): # Smaller than subphrase, so can have SPhNr and has WNr
        current["SPhNr"] = L.u('subphrase',current["Node"])
        current["WNr"] = F.etcbc4_ft_number.v(current["Node"])
        current["Phfunc"] = F.etcbc4_ft_function.v(L.u('phrase',current["Node"]))
        current["Phtype"] = F.etcbc4_ft_typ.v(L.u('phrase',current["Node"]))
    for x in (current["ClANr"],current["PhANr"],current["SPhNr"],current["WNr"]):
        if str(x).strip() in (None,"None"):
            x = 00 
            print(x)
    if current["WNr"] in (None,"None"): # Should be unnecessary after previous lines, but somewhere there is a bug an I try to find it...
        current["WNr"] = 00
    if current["Nodetype"] == "2": # Reference is a word
        current["P"] = F.etcbc4_ft_ps.v(current["Node"])
        current["N"] = F.etcbc4_ft_nu.v(current["Node"])
        current["G"] = F.etcbc4_ft_gn.v(current["Node"])
        current["Lexset"] = F.etcbc4_ft_ls.v(current["Node"])
        current["PartSpeech"] = F.etcbc4_ft_sp.v(current["Node"])
    elif current["Nodetype"] == "1": # Reference is a suffix
        current["P"] = suffix_dict[F.etcbc4_ft_prs.v(current["Node"])]['ps']    # Since the suffix_features are not yet available in the ETCBC database, we extract them from a dictionary based on surface consonants
        current["N"] = suffix_dict[F.etcbc4_ft_prs.v(current["Node"])]['nu']
        current["G"] = suffix_dict[F.etcbc4_ft_prs.v(current["Node"])]['gn']
        current["Lexset"] = "suffix"
    current["Tag"] = current["a"].rjust(15,' ') + "_" + str(current["ClANr"]).rjust(9,'0') + "_" + str(current["PhANr"]).rjust(9,'0') + "_" + str(current["WNr"]).rjust(9,'0') + "_" + str(current["Nodetype"])
    if current["Tag"] in list(cursor.execute("select Tag from pt")): # Double-check whether this work
        current["Tag"] = current["Tag"][:-1]+"0"
        if current["Tag"] in list(cursor.execute("select Tag from pt")):
            current["Tag"] = current["Tag"][:-1]+"1"
            if current["Tag"] in list(cursor.execute("select Tag from pt")):
                current["Tag"] = current["Tag"][:-1]+"2"
    if "None" in current["Tag"]:
        print("Problem!!!!!!!!!!!!!!!!! Tag is not correct!", current)
    else:
        return(current)

\end{python}

WARNING! Sometimes Tags are identical, which should not be so. Recovery function at end of document, and warnings will be given if this is happening again.

\begin{python}
def interactive_single(data,candidate):
    current = add_data(data,candidate)
    print(current["a"])
    print("clause:", get_cons_of_word_list(give_me_your_words(L.u('clause',current["Node"])))) 
    print("suffix:", current["Des"])
    current["Sub"] = input("Is this a sub-participant? Default 'Prep' ") or "Prep" 
    current["Name"] = input("What is the name of the referent? : ")
    current["Anim"] = input("1=Animate, 2=Non-animate: ")
    if current["Anim"] == "2":
        current["Human"] = "None"
    else:
        current["Human"] = input("1=Human (or divine), 2=Non-human, 3=Humans included: ")
    current["Col"] = input("Is the participant an individual (1), collective (2) or an individual in a compound design (3)? Or dual/plural?(4)")
    if current["Col"] in ("2","3","4"):
        current["Referents"] = input("Contextually relevant referents that are part of Name: ")
        current["ColPart"] = input("Contextually relevant collective of which Name is part: ") or None
    else:
        current["Referents"] = None
        current["ColPart"] = input("Contextually relevant collective of which Name is part: ") or None
    current["Role"] = input("Role in sentence? Default is Prep") or "Prep" 
    insert_dict_in_db(cursor,"pt",current)

\end{python}

\begin{python}
def interactive_clan(data,clan_members):
    format_string_a = "{0!s: <9} {1!s: <15} {2!s: <40}"
    format_string_b = "********* Nodetype: {0!s: <4}, Destype: {1!s: <4}, Name: {2!s: <10}, Anim: {3!s: <4}, Human: {4!s: <4}, Col: {5!s: <4}, Role: {6!s: <8}"
    print(data[clan_members[-1]]["a"], " Clause:", get_cons_of_word_list(give_me_your_words(L.u('clause',clan_members[-1]))))
#    print("Nodetypes: 1=Part_suffix, 2=Part_word, 3=Part_(sub)phrase, 4=Part_clause, 5=Part_sentence")
#    print("Destypes: 1=Noun, 2=Noun_phrase, 3=Name, 4=Name_phrase, 5=Pers_pronoun, 6=Demonstr_pronoun, 7=Suffix, 8=Verb, 9=Adjective")
#    print("Anim: 1=Animate, 2-Non-animate; Human: 1=Human, 2=Non-human, 3=Humans included")
#    print("Col: 1=Individual, 2=Collective, 3=Individual in compound design, 4=Plural")
    for candidate in clan_members:
        current = data[candidate]
        for x in ["Nodetype","Destype","Name","Anim","Human","Col"]:
            if not x in current:
                current[x] = None
        if F.etcbc4_db_otype.v(candidate) == "word" and not current["Nodetype"] == "1":
            current["Nodetype"] = "2"
        if current["Destype"] == "1":
            current["Nodetype"] = "2"
        if current["Anim"] == "2":
            current["Human"] = "2"
        print(format_string_a.format(candidate, current["Sub"], current["Des"]))
        print(format_string_b.format(current["Nodetype"], current["Destype"], current["Name"], current["Anim"], current["Human"], current["Col"], current["Role"]))
    clan_members2 = list(clan_members)
    for candidate in clan_members:
        current = data[candidate]
        copy = input("Do you need a copy of reference " + str(candidate) + "? Default 'N' ") or "N"
        if copy == "Y":
            copy_ref = str(candidate)+"c"
            clan_members2.append(copy_ref)
            data[copy_ref] = deepcopy(current)
            copy2 = input("Do you need another copy of reference " + str(candidate) + "? Default 'N' ") or "N"
            if copy2 == "Y":
                copy2_ref = str(candidate)+"d"
                clan_members2.append(copy2_ref)
                data[copy2_ref] = deepcopy(current)
        elif copy == "X":
            data.pop(candidate, None)
            clan_members2.remove(candidate)
            if clan_members2 == []:
                return
    clan_members3 = list(clan_members2)
    for candidate in clan_members2:
        current = data[candidate]
        for x in ["Nodetype","Destype","Name","Role"]:
            if current[x] in (None,"None"):
                current[x] = input(str(x) + " of node " + str(candidate) + ": ")
                if current["Destype"] == "X":
                    data.pop(candidate, None)
                    clan_members3.remove(candidate)
                    if clan_members3 == []:
                        return
        current["Sub"] = input("Sub of node " + str(candidate) + ", default is: " + str(current["Sub"]) + " ") or current["Sub"]
        if str(current["Name"]).endswith("!"):
            current["Name"] = current["Name"][:-1]
            Recognize = recognize2(current["Name"]) 
            if not Recognize == []:
                current["Anim"] = Recognize[0][0]
                current["Human"] = Recognize[0][1]
                current["Col"] = Recognize[0][2]
        for x in ["Anim","Human","Col"]:
            if current[x] in (None,"None"):
                current[x] = input(str(x) + " of node " + str(candidate) + ": ")
    for candidate in clan_members3:
        current = data[candidate]
        print(format_string_a.format(candidate, current["Sub"], current["Des"]))
        print(format_string_b.format(current["Nodetype"], current["Destype"], current["Name"], current["Anim"], current["Human"], current["Col"], current["Role"]))
    for candidate in clan_members3:
        current = data[candidate]
        check = input("Is the data of " + str(candidate) + " correct? Default 'Y' ") or "Y"
        while check != "Y":
            for x in ("Des","Sub","Nodetype","Destype","Name","Anim","Human","Col","Role"):
                current[x] = input(x + " of node " + str(candidate) + ", default = " + str(current[x]) + " ") or current[x] 
                if current["Destype"] == "X":
                    data.pop(candidate, None)
            print(format_string_a.format(candidate, current["Sub"], current["Des"]))
            print(format_string_b.format(current["Nodetype"], current["Destype"], current["Name"], current["Anim"], current["Human"], current["Col"], current["Role"]))
            check = input("Is the data correct? Default 'Y' ") or "Y"
        current["Referents"] = input("Contextually relevant referents that are part of Name: ") or None
        current["ColPart"] = input("Contextually relevant collective of which Name is part: ") or None
        if check == "Y":
            add_data(data,candidate)
            insert_dict_in_db(cursor,"pt",current)
            db.commit()

\end{python}

\begin{python}
def flow_clan(place, node, node_type):
    while F.etcbc4_ft_rela.v(parent[node]) == "rec" or F.etcbc4_ft_rela.v(parent[node]) == "atr": # Regens-rectum relationship or attributive relationship
        if list(C.mother.v(parent[node])) not in ([],None):
            node = list(C.mother.v(parent[node]))[0] # Deal with the clan-head instead of a (grand)child
    clan = {}
    clan_members = []
    data = {}
    if not F.etcbc4_ft_g_cons.v(node) == get_cons_of_word_list(give_me_your_words(parent[node])) and not F.etcbc4_ft_sp.v(give_me_your_words(parent[node])[0]) == "prep":
        clan[parent[node]] = "Super "
        clan[node] = "Sub1 "
    else:
        clan[node] = None
    for candidate in give_me_your_daughters(node):
        if F.etcbc4_db_otype.v(candidate) == "subphrase" and F.etcbc4_ft_rela.v(candidate) == "rec":
            clan[candidate] = "Rec "
        elif F.etcbc4_db_otype.v(candidate) == "subphrase" and F.etcbc4_ft_rela.v(candidate) == "atr":
            clan[candidate] = "Attr "
        if len(L.d('word',candidate)) == 1 and get_cons_of_word_list(give_me_your_words(candidate)) == F.etcbc4_ft_g_cons.v(L.d('word',candidate)[0]):
            clan[L.d('word',candidate)[0]] = deepcopy(clan[candidate])
            del clan[candidate]
            candidate = L.d('word',candidate)[0] 
        for x in C.mother.v(candidate):
            if not parent[x] in clan:
                clan[parent[x]] = "Super "
    for candidate in clan:
        clan_members.append(candidate)
        subdata = deepcopy(clan[candidate])
        data[candidate] = prepare(place, candidate, "word+", subdata)
        if not F.etcbc4_ft_prs.v(candidate) in ("absent","n/a",None):
            candidate2 = str(candidate)+"s"
            clan_members.append(candidate2)
            data[candidate2] = prepare(place, candidate2, "suffix", subdata)
    interactive_clan(data,clan_members)

\end{python}

\begin{python}
# Basic script: record some statistics and filter potential participant references
DSU = False
completed = False
potential_ref = False
potential_suffix = False
data = {}

limit = 0
for node in NN():
    otype = F.etcbc4_db_otype.v(node)
    if otype == "book" and F.etcbc4_sft_book.v(node) != "Genesis":
        break
    elif otype == "chapter":
        if int(F.etcbc4_sft_chapter.v(node)) < 19:    # Prevent re-doing already completed chapters
            completed = True
#        elif int(F.etcbc4_sft_chapter.v(node)) > 3:    # Set a limit on the amount of data dealt with this time
#            break
        else:
            completed = False 
    elif otype == "verse":
#        if int(F.etcbc4_sft_verse.v(node)) < 22:
#           completed = True
#        else:
#           completed = False
        if completed == False:
            place = F.etcbc4_sft_label.v(node)
    elif otype == "clause" and completed == False:
        DSU = (F.etcbc4_ft_txt.v(node).count("Q") > 0)    # If the text_type contains a Q, we consider the clause as Direct Speech
    elif F.etcbc4_db_otype.v(node) == "word" and DSU == True and completed == False:
        check_node = str(node)
#        if check_node != "":     # Just a hack when temporarily outcommenting lines below
        cursor.execute("SELECT EXISTS (SELECT * FROM pt WHERE Node = " + check_node + ");") # Check whether reference is not yet saved in database
        result = cursor.fetchone()
#        if result == "(0,)":
        potential_ref = False
        potential_suffix = False
        if not (F.etcbc4_ft_ps.v(node) in ("unknown", "NA") and F.etcbc4_ft_nu.v(node) in ("unknown","NA") and F.etcbc4_ft_gn.v(node) in ("unknown","NA")):
            potential_ref = True
        if not F.etcbc4_ft_prs.v(node) in ("absent","n/a"):
            potential_suffix = True
        if result == (0,) and potential_ref == True: # Not yet saved, to be dealt with in flow_clan (may have suffixes as well, these will be parsed within the flow)
            flow_clan(place, node, "word")
        if result == (0,) and potential_ref == False and potential_suffix == True: # Not yet saved, not to be dealt with in flow_clan, but suffix needs to be parsed
            candidate = str(node)+"s"
            data[candidate] = prepare(place, node, "single_suffix", "Prep")
            interactive_single(data,candidate)

\end{python}

\begin{python}
#{{{ Commit and close the database
db.commit()
db.close()
#}}}
\end{python}

\chapter{Part-2.py}
\begin{python}
# Load database
import json as j
import sqlite3

db = sqlite3.connect('gcdata.sqlite')
#db.row_factory = sqlite3.Row
c = db.cursor()

\end{python}

From gcdata.gcdsu we want to extract the \mi{DSU_Tag}, so that we can easily see
whether various participant references occur in the same DSU or in a different one.
For each DSU we create a dictionary item with its \mi{Tag}, \mi{place} and \mi{clause_atom_numbers}.
We then check of which DSU the \mi{clause_atom_number} of the current participant
reference is part, and store its \mi{Tag} in the column \mi{DSU}.

\begin{python}
# Assign DSU and Level
DSU_Tags = list(cursor.execute("select DSUtag,Level,ClANrs from gcdsu"))
pts = list(cursor.execute("select Tag,a,ClANr from pt where DSU is null or DSU = ''"))

DSU = {}

for (Tag,a,ClANr) in pts:
    for (DSUtag,Level,ClANrs) in DSU_Tags:
        if str(ClANr) in ClANrs.split(","):
            cursor.execute("update pt set DSU=:DSUtag,Level=:Level where a=:a and ClANr=:ClANr", {"DSUtag":DSUtag,"Level":Level,"a":a,"ClANr":str(ClANr)})
            DSU[Tag] = DSUtag

\end{python}

\begin{python}
# Feed participants back to DSU
DSU_todo = list(cursor.execute("select DSUtag from gcdsu where Part is NULL or Part = '' or Part = '[]'"))

for (DSUtag,) in DSU_todo:
    print(DSUtag)
    parts = []
    data = []
    references = list(cursor.execute("select Tag,Name,Referents,ColPart from pt where DSU=:DSU", {"DSU":DSUtag, }))
    for (Tag,Name,Referents,ColPart) in references:
        if not Name in ("None",None):
            for x in Name.split(","):
                if not x.strip() in parts:
                    parts.append(x)
        if not Referents in ("None",None):
            for x in Referents:
                for y in x:
                    for z in y.split(","):
                        if not z.strip() in parts:
                            parts.append(z.strip())
        if not ColPart in ("None",None):
            for x in ColPart:
                for y in x:
                    for z in y.split(","):
                        if not z.strip() in parts:
                            parts.append(z.strip())
    cursor.execute("update gcdsu set Part=:Part where DSUtag=:DSUtag", {"Part":str(parts), "DSUtag":DSUtag})

\end{python}

In order to facilitate the combination of information between SQlite rows,
we assign a number to each participant reference, indicating how many times
this participant has been referred to, including the current reference.
Later on, we can then identify the \mi{Ref}-values by selecting values with the
same \mi{Name} and a \mi{Nr} that is 1 lower than the current \mi{Nr}.
A difficulty arises when a participant is referred to as part of a group,
e.g. ``God said to them...'' meaning both the man and the woman of \bibleverse{Gen}[1].
Therefore I provide two kinds of information:
\begin{itemize}
\item A \mi{Nr} that indicates the number of occurrences of exactly the same referent. This is relevant for \mi{Prev}-data and \mi{Ref}-data.
\item I mention the names of relevant referents that are included in other referents etc in the column \mi{Referents}, so that these can be counted and processed later on (e.g. to see how often someone is referred to in a particular DSU).
\end{itemize}
Note: In de first 15 chapters of Genesis, this data has not been entered consistently. This needs to be checked.
Remark / question: What to do with sub-participants like possessive pronouns?
Another aspect that adds complexity, is the occurrence of sub-participants.
I do not count them in the column \mi{Nr}, but their name is stored in the columns
\mi{Name} and \mi{Referents}.


\begin{python}
#{{{ Assign Nr - new try
nrs_todo = list(cursor.execute("select Sub, Name, Tag, Nr from pt where Nr is null or Nr = ''"))  # Select all rows that need a Nr
nrs = {}    # Create dict for all relevant Names + their Nrs

for (Sub, Name, Tag, Nr) in nrs_todo:
    Name = str(Name).strip()
    if not str(Sub).strip().endswith('Sub1'):
        if Name in nrs:
            newnr = nrs[Name] + 1
        elif Name not in nrs:
            oldnr = list(cursor.execute("select Nr from pt where Name=:Name and not Nr is NULL ORDER BY Tag DESC LIMIT 1", {"Name":Name,}))
            if oldnr in ([],None) or oldnr[0][0] in ('',None):
                newnr = 1
            else:
                newnr = int(oldnr[0][0]) + 1
        nrs[Name] = newnr
        cursor.execute("update pt set Nr=:newnr where Tag=:Tag", {"newnr":newnr, "Tag":Tag})
        print(Name,Sub,nrs[Name])

#}}}
\end{python}

Below we do a for-loop over all rows in gcdata.pt that still miss certain data,
and update them with information about the preceding reference to this participant (\mi{Ref}),
the previous reference (irrespective of the participant) (\mi{Prev}) and the first reference
to this participant (\mi{1}).

We repeat the process for other information. Putting all these columns in one
for-loop would overload them and make the code unclear.

\begin{python}
#{{{ Update Ref, Prev and *1-data
all_tags = list(cursor.execute("select Tag from pt ORDER BY Tag"))
todo = list(cursor.execute("select Tag,Name,Nr from pt where RefNode is null or RefNode = ''"))

for (Tag,Name,Nr) in todo:
    Refdata = list(cursor.execute("select DSU, a, ClANr, PhANr, Node, Nodetype, WNr from pt where Name=:Name ORDER BY Tag DESC LIMIT 1", {"Name":Name, })) # Ref-data
    cursor.execute("update pt set RefDSU=:DSU, Refa=:a, RefClANr=:ClANr, RefPhANr=:PhANr, RefNode=:Node, RefNodetype=:Nodetype, RefWNr =:WNr where Name=:Name and Nr=:Nr",{"DSU":Refdata[0][0],"a":Refdata[0][1],"ClANr":Refdata[0][2],"PhANr":Refdata[0][3],"Node":Refdata[0][4],"Nodetype":Refdata[0][5],"WNr":Refdata[0][6],"Name":Name,"Nr":Nr}) 
    Onedata = list(cursor.execute("select DSU, a, ClANr, PhANr, Node, Nodetype, WNr from pt where Name=:Name ORDER BY Tag LIMIT 1", {"Name":Name, })) # *1-data
    cursor.execute("update pt set DSU1=:DSU, a1=:a, ClANr1=:ClANr, PhANr1=:PhANr, Node1=:Node, Nodetype1=:Nodetype, WNr1=:WNr where Name=:Name and Nr=:Nr",{"DSU":Onedata[0][0],"a":Onedata[0][1],"ClANr":Onedata[0][2],"PhANr":Onedata[0][3],"Node":Onedata[0][4],"Nodetype":Onedata[0][5],"WNr":Onedata[0][6],"Name":Name,"Nr":Nr}) 

    index = [y[0] for y in all_tags].index(Tag)  # Check the index of this row in the ordered list all_tags, in order to find the previous row = Prev_data 
    if index == 0:  # Apparently this is the first row of the table
        Prevdata = list(cursor.execute("select Name, DSU, a, ClANr, PhANr, Node, Nodetype, WNr from pt where Tag=:Tag",{"Tag":Tag, })) # Prev-data for first entry
    else:
        prev_Tag = all_tags[(index-1)][0]
        Prevdata = list(cursor.execute("select Name, DSU, a, ClANr, PhANr, Node, Nodetype, WNr from pt where Tag=:prev_Tag",{"prev_Tag":prev_Tag, })) # Prev-data
    cursor.execute("update pt set PrevName =:PrevName, PrevDSU=:DSU, Preva=:a, PrevClANr=:ClANr, PrevPhANr=:PhANr, PrevNode=:Node, PrevNodetype=:Nodetype, PrevWNr =:WNr where Name=:Name and Nr=:Nr",{"PrevName":Name,"DSU":Prevdata[0][0],"a":Prevdata[0][1],"ClANr":Prevdata[0][2],"PhANr":Prevdata[0][3],"Node":Prevdata[0][4],"Nodetype":Prevdata[0][5],"WNr":Prevdata[0][6],"Name":Name,"Nr":Nr}) 

for (Tag,Name,Nr) in todo:
    Refdata = list(cursor.execute("select Con, Level, Emb, Des, Destype, Role, P, N, G, Lexset, PartSpeech from pt where Name=:Name ORDER BY Tag DESC LIMIT 1", {"Name":Name, })) # Ref-data
    cursor.execute("update pt set RefCon=:Con, RefLevel=:Level, RefEmb=:Emb, RefDes=:Des, RefDestype=:Destype, RefRole=:Role, RefP=:P, RefN=:N, RefG=:G, RefLexset=:Lexset, RefPartSpeech=:PartSpeech where Name=:Name", {"Con":Refdata[0][0],"Level":Refdata[0][1],"Emb":Refdata[0][2],"Des":Refdata[0][3],"Destype":Refdata[0][4],"Role":Refdata[0][5],"P":Refdata[0][6],"N":Refdata[0][7],"G":Refdata[0][8],"Lexset":Refdata[0][9],"PartSpeech":Refdata[0][10],"Name":Name})
    index = [y[0] for y in all_tags].index(Tag)  # Check the index of this row in the ordered list all_tags, in order to find the previous row = Prev_data 
    if index == 0:  # Apparently this is the first row of the table
        Prevdata = list(cursor.execute("select Con, Level, Emb, Des, Destype, Role, P, N, G, Lexset, PartSpeech from pt where Tag=:Tag",{"Tag":Tag, })) # Prev-data for first entry
    else:
        prev_Tag = all_tags[(index-1)][0]
        Prevdata = list(cursor.execute("select Con, Level, Emb, Des, Destype, Role, P, N, G, Lexset, PartSpeech from pt where Tag=:prev_Tag",{"prev_Tag":prev_Tag, })) # Prev-data
    cursor.execute("update pt set PrevCon=:Con, PrevLevel=:Level, PrevEmb=:Emb, PrevDes=:Des, PrevDestype=:Destype, PrevRole=:Role, PrevP=:P, PrevN=:N, PrevG=:G, PrevLexset=:Lexset, PrevPartSpeech=:PartSpeech where Tag=:Tag", {"Con":Prevdata[0][0],"Level":Prevdata[0][1],"Emb":Prevdata[0][2],"Des":Prevdata[0][3],"Destype":Prevdata[0][4],"Role":Prevdata[0][5],"P":Prevdata[0][6],"N":Prevdata[0][7],"G":Prevdata[0][8],"Lexset":Prevdata[0][9],"PartSpeech":Prevdata[0][10],"Tag":Tag})
#}}}
\end{python}

\end{document}
#sagemathcloud={"latex_command":"pdflatex -synctex=1 -shell-escape -interact=nonstopmode 'workflow2.tex'"}


\begin{python}
# Recovery function
todo = list(cursor.execute("select ClANr,Node from pt;"))
for (ClANr,Node) in todo:
    print(ClANr, Node, F.etcbc4_db_otype.v(int(Node or 0)))
    print("ClANr is now: ",L.u('clause_atom',int(Node or 0)))
    cursor.execute("update pt set ClANr=:ClANr where Node=:Node", {"ClANr":L.u('clause_atom',int(Node or 0)),"Node":Node})

\end{python}
\begin{python}
# Recovery function
#todo = list(cursor.execute("select Node,Tag,a,ClANr,PhANr,WNr,Nodetype from pt where WNr is NULL or WNr = 'None'"))
todo = list(cursor.execute("select Node,Tag,a,ClANr,PhANr,WNr,Nodetype from pt where Node = '7514' or Node = '7517' or Node = '7520' or Node = '7521' or Node = '1262342'"))

for (Node,Tag,a,ClANr,PhANr,WNr,Nodetype) in todo:
    ClANr2 = L.u('clause_atom',int(Node))
    if ClANr2 == None:
        ClANr2 = 00
    PhANr2 = L.u('phrase',int(Node))
    if PhANr2 == None:
        if F.etcbc4_db_otype.v(int(Node)) in ('phrase','subphrase'):
            PhANr2 = Node
        else:
            PhANr2 = 00
    WNr2 = L.u('word',int(Node))
    if WNr2 == None:
        if F.etcbc4_db_otype.v(int(Node)) == 'word':
            WNr2 = Node
        else:
            WNr2 = 00
#        print(Tag,ClANr,ClANr2,PhANr,WNr)
    newtag = a.rjust(15,' ') + "_" + str(ClANr2).rjust(9,'0') + "_" + str(PhANr2).rjust(9,'0') + "_" + str(WNr2).rjust(9,'0') + "_" + str(Nodetype)
    print(Node,F.etcbc4_db_otype.v(int(Node)),Tag,newtag)
#    if PhANr != PhANr2:
#        print(PhANr,PhANr2)
#    if WNr != WNr2:
#        print(WNr,WNr2)
    cursor.execute("update pt set PhANr=:PhANr2, WNr=:WNr2, Tag=:Tag where Node=:Node", {"PhANr2":PhANr2,"WNr2":WNr2,"Tag":newtag,"Node":Node})

\end{python}

\begin{python}
# Recovery function for Cltype and Phtype
todo = list(c.execute("select Node,Nodetype from pt where Phtype is NULL;"))
for (Node,Nodetype) in todo:
    if Nodetype == "4":
        Cltype = F.etcbc4_ft_typ.v(int(Node))
    elif Nodetype in ("1","2","3"):
        Cltype = F.etcbc4_ft_typ.v(L.u('clause',int(Node)))
    if Nodetype == "3":
        Phtype = F.etcbc4_ft_typ.v(int(Node))
    elif Nodetype in ("1","2") or Phtype is None:
        Phtype = F.etcbc4_ft_typ.v(L.u('phrase',int(Node)))
    print(Node,Nodetype,Cltype,Phtype)
    c.execute("update pt set Cltype=:Cltype, Phtype=:Phtype where Node=:Node and Nodetype=:Nodetype", {"Cltype":Cltype, "Phtype":Phtype, "Node":Node, "Nodetype":Nodetype})

\end{python}

\begin{python}
# Test function
done = []
test = list(c.execute("select * from pt"))
for i in range(84):
    todo = True
    for x in test:
        if x[i] == None:
            todo = True
        else: 
            todo = False
            done.append(i)
            break

print("done: ",done)
for i in range(84):
    if not i in done:
        print("todo: ", i)
\end{python}

\begin{python}
# Function to test for identical Tags (which should not occur)
Tags = []
double = []
data = list(cursor.execute("select ID,Tag from pt"))
for (ID,Tag) in data:
    if Tag in Tags:
        double.append((ID,Tag))
    else:
        Tags.append(Tag)

for (ID,Tag) in double:
    Tag = str(Tag) +"0"
    cursor.execute("update pt set Tag=:Tag where ID=:ID",{"Tag":Tag,"ID":"ID"})

\end{python}
